{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Naïve Compression of DNA Sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification of Information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information theory is based on the observation that knowing that a likely event has occurred is less informative than knowing that an unlikely event has occurred.\n",
    "\n",
    "A quantification of information should have the following properties:\n",
    "- Likely events should have a low information content, and events that are certain to occur should have no information content at all. Less likely events should have a higher information content.\n",
    "- Independent events should have additive information content.\n",
    "\n",
    "The self-information of an event $x$ is hence defined as\n",
    "\n",
    "$$I(x)=-\\log{}P(x).$$\n",
    "\n",
    "By using the base-2 logarithm, the unit of self-information is bit.\n",
    "Hence, one bit is the amount of information gained by observing an event of probability $\\frac{1}{2}$.\n",
    "\n",
    "Self-information deals only with a single event $x$.\n",
    "By computing the expectation of the self-information with respect to the entire probability distribution $P(\\text{x})$ we obtain the entropy\n",
    "\n",
    "$$H(\\text{x})=\\mathbb{E}_{\\text{x}\\sim{}P}[I(\\text{x}=x)]=-\\mathbb{E}_{\\text{x}\\sim{}P}[\\log{}P(\\text{x}=x)]=-\\sum_{x}P(x)\\log{}P(x).$$\n",
    "\n",
    "The entropy gives the average information that is expected in an event $x$ drawn from probability distribution $P(\\text{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Computing entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function `entropy()` to compute the entropy of the given sequence.\n",
    "Then, compute the entropy in bit per symbol of the sequences `AAAA`, `AACC`, `ACGT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "\n",
    "def entropy(data: Any, base: int = 2) -> float:\n",
    "    \"\"\"Compute the entropy of a list of data.\"\"\"\n",
    "    if len(data) <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    counts = collections.Counter()\n",
    "    for datum in data:\n",
    "        counts[datum] += 1\n",
    "\n",
    "    eta = 0.0\n",
    "    probs = [(float(c) / len(data)) for c in counts.values()]\n",
    "    for prob in probs:\n",
    "        if prob > 0.0:\n",
    "            eta -= prob * math.log(prob, base)\n",
    "\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of 'AAAA': 0.00 bit/symbol\n",
      "Entropy of 'AACC': 1.00 bit/symbol\n",
      "Entropy of 'ACGT': 2.00 bit/symbol\n"
     ]
    }
   ],
   "source": [
    "for sequence in [\"AAAA\", \"AACC\", \"ACGT\"]:\n",
    "    eta = entropy(data=sequence)\n",
    "    print(f\"Entropy of '{sequence}': {round(eta, 2):.2f} bit/symbol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The FASTQ Format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [FASTQ format](https://en.wikipedia.org/wiki/FASTQ_format) is the de-facto standard for storing both a biological sequence (usually nucleotide sequence) and its corresponding quality scores.\n",
    "Both the sequence letter and quality score are each encoded with a single ASCII character.\n",
    "\n",
    "Each sequence, i.e., read, is represented by a single FASTQ record, which consists of four lines:\n",
    "- The first line contains the **read identifier**. It starts with `@`. Typically, sequencing machine vendors generate read identifiers in a proprietary systematic way.\n",
    "- The second line contains the **sequence**, where each symbol is represented with a single ASCII character.\n",
    "- The third line starts with `+` and contains an optional **description**. Usually this line is left empty; it then only contains `+` as separator between the sequence and the quality scores.\n",
    "- The fourth line contains the **quality scores**. A quality score is a value indicating the confidence in a base call.\n",
    "\n",
    "The following function can be used to convert a FASTQ record into a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastq_lines_to_dict(lines: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"Convert a list of FASTQ lines to a dictionary.\"\"\"\n",
    "    keys = [\"id\", \"seq\", \"desc\", \"qual\"]\n",
    "    return dict(zip(keys, lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Parsing a FASTQ file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following code to parse the FASTQ file `example.fastq`.\n",
    "Print all FASTQ records in the following format:\n",
    "\n",
    "```\n",
    "Record 0: {'id': '@id0', 'seq': 'GATTTG...', 'desc': '+', 'qual': \"!''*((...\"}\n",
    "Record 1: {'id': '@id1', 'seq': 'GATTTG...', 'desc': '+', 'qual': \"!''*((...\"}\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record  0: {'id': '@id00', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record  1: {'id': '@id01', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record  2: {'id': '@id02', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record  3: {'id': '@id03', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record  4: {'id': '@id04', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record  5: {'id': '@id05', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record  6: {'id': '@id06', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record  7: {'id': '@id07', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record  8: {'id': '@id08', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record  9: {'id': '@id09', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record 10: {'id': '@id10', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n",
      "Record 11: {'id': '@id11', 'seq': 'GATTTGGGGTTCAAAGCAGTATCGATCAAATA', 'desc': '+', 'qual': \"!''*((((***+))%%%++)(%%%%).1***-\"}\n"
     ]
    }
   ],
   "source": [
    "def read_fastq_file(file_path: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Read a FASTQ file and return a list of records.\"\"\"\n",
    "    with open(file=file_path, mode=\"r\") as file:\n",
    "        records = []\n",
    "        lines = []\n",
    "        for line in file:\n",
    "            lines.append(line.rstrip())\n",
    "            if (len(lines)) == 4:\n",
    "                records.append(fastq_lines_to_dict(lines=lines))\n",
    "                lines = []\n",
    "\n",
    "        return records\n",
    "\n",
    "\n",
    "records = read_fastq_file(file_path=\"data/example.fastq\")\n",
    "for i, record in enumerate(records):\n",
    "    print(f\"Record {i:2}: {record}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression of Nucleotide Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ❓ Compressing DNA sequence reads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all nucleotide sequences from the FASTQ file `example.fastq`.\n",
    "Compute the entropy (in bit per symbol) and the maximum (worst-case) compressed size in bit and byte.\n",
    "\n",
    "> The assumption here is that every well-designed compressor that makes uses of any statistics beyond the per-symbol probabilites must yield a compressed bitstream that is smaller or equal to the entropy.\n",
    "\n",
    "Then, use gzip to beat the estimated worst-case compression.\n",
    "\n",
    "> Use the functions `gzip.compress()` and `gzip.decompress()`.\n",
    "> Use UTF-8 encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated sequence length: 384\n",
      "Entropy: 1.92 bit/symbol\n",
      "Maximum compressed size: 738 bit ≙93 byte\n",
      "Worst-case compression ratio: 4.1x\n",
      "Gzip compression ratio: 7.4x\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "# Concatenate all sequences.\n",
    "seq = \"\"\n",
    "for record in records:\n",
    "    seq += record[\"seq\"]\n",
    "seq_len = len(seq)\n",
    "print(f\"Concatenated sequence length: {seq_len}\")\n",
    "\n",
    "# Compute the entropy (in bit per symbol) and the maximum (worst-case) compressed size\n",
    "# in bit and byte.\n",
    "eta = entropy(data=seq)\n",
    "max_compressed_size_in_bit = math.ceil(eta * seq_len)\n",
    "max_compressed_size_in_byte = math.ceil(max_compressed_size_in_bit / 8)\n",
    "print(f\"Entropy: {round(number=eta, ndigits=2):.2f} bit/symbol\")\n",
    "print(\n",
    "    f\"Maximum compressed size: \"\n",
    "    f\"{max_compressed_size_in_bit} bit \\u2259\"\n",
    "    f\"{max_compressed_size_in_byte} byte\"\n",
    ")\n",
    "print(f\"Worst-case compression ratio: {seq_len / max_compressed_size_in_byte:.1f}x\")\n",
    "\n",
    "# Use gzip to beat the estimated worst-case compression.\n",
    "compressed_seq = gzip.compress(data=bytes(seq, encoding=\"utf-8\"))\n",
    "decompressed_seq = gzip.decompress(data=compressed_seq).decode(encoding=\"utf-8\")\n",
    "print(f\"Gzip compression ratio: {seq_len / len(compressed_seq):.1f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
